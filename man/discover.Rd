% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/discover.r
\encoding{UTF-8}
\name{discover}
\alias{discover}
\title{Dependency discovery with DFD}
\usage{
discover(
  df,
  accuracy,
  method = c("dfd", "tane"),
  full_cache = TRUE,
  store_cache = TRUE,
  skip_bijections = FALSE,
  exclude = character(),
  exclude_class = character(),
  progress = FALSE,
  progress_file = ""
)
}
\arguments{
\item{df}{a data.frame, the relation to evaluate.}

\item{accuracy}{a numeric in (0, 1]: the accuracy threshold required in order
to conclude a dependency.}

\item{method}{a character, indicating which search algorithm to use. The two
available choices are DFD and Tane, depth-first and breadth-first searches
on the determinant powerset.}

\item{full_cache}{a logical, indicating whether to store information about
how sets of attributes group the relation records (stripped partitions).
Otherwise, only the number of groups is stored. Storing the stripped
partition is expected to let the algorithm run more quickly, but might be
inefficient for small data frames or small amounts of memory.}

\item{store_cache}{a logical, indicating whether to keep cached information
to use when finding dependencies for other dependents. This allows the
algorithm to run more quickly by not having to re-calculate information,
but takes up more memory.}

\item{skip_bijections}{a logical, indicating whether to skip some dependency
searches that are made redundant by discovered bijections between
attributes. This can significantly speed up the search if \code{df}
contains equivalent attributes early in column order, but results in
undefined behaviour if \code{accuracy < 1}. See Details for more
information.}

\item{exclude}{a character vector, containing names of attributes to not
consider as members of determinant sets. If names are given that aren't
present in \code{df}, the user is given a warning.}

\item{exclude_class}{a character vector, indicating classes of attributes to
not consider as members of determinant_sets. Attributes are excluded if
they inherit from any given class.}

\item{progress}{a logical, for whether to display progress to the user during
dependency search in \code{\link{discover}}.}

\item{progress_file}{a scalar character or a connection. If \code{progress}
is non-zero, determines where the progress is written to, in the same way
as the \code{file} argument for \code{\link[base]{cat}}.}
}
\value{
A \code{\link{functional_dependency}} object, containing the discovered
dependencies. The column names of \code{df} are stored in the \code{attrs}
attribute, in order, to serve as a default priority order for the
attributes during normalisation.
}
\description{
Finds all the minimal functional dependencies represented in a data frame.
}
\details{
Column names for \code{\link{df}} must be unique.

There are two supplied algorithms for finding dependencies: DFD and Tane.
These both search for determinant sets for each dependent attribute by
traversing the powerset of the other (non-excluded) attributes, and are
equivalent to depth-first and breadth-first search, respectively. Tane is the
simpler approach, but can be significantly slower if there are large
non-determinant sets.

The implementation for DFD differs a little from the algorithm presented in
the original paper:
\itemize{
\item Some attributes, or attribute types, can be designated, ahead of
time, as not being candidate members for determinant sets. This reduces the
number of candidate determinant sets to be searched, saving time by not
searching for determinant sets that the user would remove later anyway.
\item Attributes that have a single unique value, i.e. are
constant, get attributed a single empty determinant set. In the standard
DFD algorithm, they would be assigned all the other non-excluded attributes
as length-one determinant sets. Assigning them the empty set distinguishes
them as constant, allowing for special treatment at normalisation and later
steps.
\item As was done in the original Python library, there is an extra case in
seed generation for when there are no discovered maximal non-dependencies.
In this case, we take all of the single-attribute nodes, then filter out by
minimal dependencies as usual. This is equivalent to taking the empty set
as the single maximal non-dependency.
\item There are three results when checking whether a candidate node is
minimal/maximal. TRUE indicates the node is minimal/maximal, as usual.
FALSE has been split into FALSE and NA. NA indicates that we can not yet
determine whether the node is minimal/maximal. FALSE indicates that we have
determined that it is not minimal/maximal, and we can set its category as
such. This is done by checking whether any of its adjacent
subsets/supersets are dependencies/non-dependencies, instead of waiting to
exhaust the adjacent subsets/supersets to visit when picking the next node
to visit.
\item We do not yet keep hashmaps to manage subset/superset relationships,
as described in Section 3.5 of the original paper.
\item \code{skip_bijections} allows for additional optimisation for finding
functional dependencies when there are pairwise-equivalent attributes.
\item Missing values (NA) are treated as a normal value, with NA = NA being
true, and x = NA being false for any non-NA value of x.
}

Skipping bijections allows skipping redundant searches. For example, if the
search discovers that \code{A -> B} and \code{B -> A}, then only one of those
attributes is considered for the remainder of the search. Since the search
time increases exponentially with the number of attributes considered, this
can significantly speed up search times. At the moment, this is only be done
for bijections between single attributes, such as \code{A <-> B}; if \code{A
<-> {B, C}}, nothing is skipped. Whether bijections are skipped doesn't
affect which functional dependencies are present in the output, but it might
affect their order.

Skipping bijections for approximate dependencies, i.e. when \code{accuracy < 1},
should be avoided: it can result in incorrect output, since an approximate
bijection doesn't imply equivalent approximate dependencies.
}
\examples{
# simple example
discover(ChickWeight, 1)

# example with spurious dependencies
discover(CO2, 1)
# exclude attributes that can't be determinants.
# in this case, the numeric attributes are now
# not determined by anything, because of repeat measurements
# with no variable to mark them as such.
discover(CO2, 1, exclude_class = "numeric")
}
\references{
Abedjan Z., Schulze P., Naumann F. (2014) DFD: efficient functional
dependency discovery. \emph{Proceedings of the 23rd ACM International Conference
on Conference on Information and Knowledge Management (CIKM '14). New York,
U.S.A.}, 949--958.

Huhtala Y., Kärkkäinen J., Porkka P., Toivonen H. (1999) Tane: An Efficient
Algorithm for Discovering Functional and Approximate Dependencies.
\emph{Comput. J.}, \strong{42, 2}, 100--111.
}
